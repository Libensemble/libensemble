{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate Model with gpCAM \n",
    "\n",
    "This example uses [gpCAM](https://github.com/lbl-camera/gpCAM) to construct a global surrogate of ``f`` values using a Gaussian process.\n",
    "\n",
    "In each iteration, a batch of points is produced for concurrent evaluation, maximizing uncertainty reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Beginning\n",
    "\n",
    "Ensure that libEnsemble, and gpCAM are installed via: `pip install libensemble gpcam`\n",
    "    \n",
    "> **Note that for notebooks** the multiprocessing start method should be set to `fork` (default on Linux).\n",
    "> To use with `spawn` (default on Windows and macOS), use the `multiprocess` library.\n",
    "\n",
    "> **Note:** If using **Colab** the cell below installs gpCAM and prevents Colab downgrading numpy due to pre-installs.\n",
    "> Restart session when prompted (the warnings can be ignored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install libensemble\n",
    "    # !pip install gpcam\n",
    "    # Prevent downgraded numpy in colab due to preinstalls\n",
    "    !pip install --upgrade --force-reinstall numpy==2.1.1 scipy gpcam fvgp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator function\n",
    "\n",
    "The gpCAM generator function is called ``persistent_gpCAM``.\n",
    "\n",
    "This persistent generator is started at the beginning and runs until the Ensemble closes down.\n",
    "\n",
    "This is a version of the gpCAM generator that can be found, along with other gpCAM generator functions, at [libensemble/gen_funcs/persistent_gpCAM.py](https://github.com/Libensemble/libensemble/blob/main/libensemble/gen_funcs/persistent_gpCAM.py) and can be imported from that location when libEnsemble is installed as follows:\n",
    "\n",
    "``from libensemble.gen_funcs.persistent_gpCAM import persistent_gpCAM``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.recfunctions import repack_fields\n",
    "from gpcam import GPOptimizer as GP\n",
    "\n",
    "# Standard options for manager/generator comms\n",
    "from libensemble.message_numbers import EVAL_GEN_TAG, FINISHED_PERSISTENT_GEN_TAG, PERSIS_STOP, STOP_TAG\n",
    "from libensemble.tools.persistent_support import PersistentSupport\n",
    "\n",
    "def persistent_gpCAM(H_in, persis_info, gen_specs, libE_info):\n",
    "    \"\"\"Run a batched gpCAM model to create a surrogate\"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    rng, batch_size, n, lb, ub, x_new, y_new, ps = _initialize_gpcAM(gen_specs[\"user\"], libE_info)\n",
    "    ask_max_iter = gen_specs[\"user\"].get(\"ask_max_iter\") or 10\n",
    "    test_points = _read_testpoints(gen_specs[\"user\"])\n",
    "    noise = 1e-8  # Initializes noise\n",
    "    my_gp = None\n",
    "    \n",
    "    # Start with a batch of random points\n",
    "    x_new = rng.uniform(lb, ub, (batch_size, n))\n",
    "    H_o = np.zeros(batch_size, dtype=gen_specs[\"out\"])    \n",
    "    H_o[\"x\"] = x_new\n",
    "    tag, Work, calc_in = ps.send_recv(H_o)  # Send random points for evaluation and wait for results\n",
    "\n",
    "    while tag not in [STOP_TAG, PERSIS_STOP]:\n",
    "        y_new = np.atleast_2d(calc_in[\"f\"]).T\n",
    "        my_gp = _update_gp(my_gp, x_new, y_new, test_points, persis_info, noise)\n",
    "\n",
    "        # Request new points\n",
    "        x_new = my_gp.ask(\n",
    "            input_set=np.column_stack((lb, ub)),\n",
    "            n=batch_size,\n",
    "            pop_size=batch_size,\n",
    "            acquisition_function=\"total correlation\",\n",
    "            max_iter=ask_max_iter,  # Larger takes longer. gpCAM default is 20.\n",
    "        )[\"x\"]\n",
    "        \n",
    "        H_o = np.zeros(batch_size, dtype=gen_specs[\"out\"])\n",
    "        H_o[\"x\"] = x_new\n",
    "        tag, Work, calc_in = ps.send_recv(H_o)  # Send points for evaluation and wait for results\n",
    "\n",
    "    # If final points were returned update the model\n",
    "    if calc_in is not None:\n",
    "        y_new = np.atleast_2d(calc_in[\"f\"]).T\n",
    "        my_gp = _update_gp(my_gp, x_new, y_new, test_points, persis_info, noise)\n",
    "\n",
    "    return None, persis_info, FINISHED_PERSISTENT_GEN_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common acquisition functions include:\n",
    "\n",
    "**Uncertainty reduction:**\n",
    "- **\"variance\"** (default): The optimizer will find N best points.Â \n",
    "- **\"total correlation\"**: More expensive but points found are self-avoiding.\n",
    "\n",
    "**Bayesian optimization:**\n",
    "\n",
    "These produce one point at a time unless using the [HGDL](https://ieeexplore.ieee.org/abstract/document/9652812) option.\n",
    "- **\"ucb\" / \"lcb\"**: Upper/Lower Confidence Bound.\n",
    "- **\"expected improvement\"**: Expected Improvement.\n",
    "\n",
    "For more options see: https://gpcam.lbl.gov/examples/acquisition-functions\n",
    "\n",
    "---\n",
    "\n",
    "The following cell adds the functions used by `persistent_gpCAM`.\n",
    "\n",
    "`_update_gp` is where the GP is fed the data and trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialize_gpcAM(user_specs, libE_info):\n",
    "    \"\"\"Extract user params\"\"\"\n",
    "    rng_seed = user_specs.get(\"rng_seed\")  # will default to None\n",
    "    rng = np.random.default_rng(rng_seed)  # Create random stream\n",
    "    b = user_specs[\"batch_size\"]\n",
    "    lb = np.array(user_specs[\"lb\"])\n",
    "    ub = np.array(user_specs[\"ub\"])\n",
    "    n = len(lb)  # no. of dimensions\n",
    "    init_x = np.empty((0, n))\n",
    "    init_y = np.empty((0, 1))\n",
    "    ps = PersistentSupport(libE_info, EVAL_GEN_TAG)  # init comms\n",
    "    return rng, b, n, lb, ub, init_x, init_y, ps\n",
    "\n",
    "\n",
    "def _read_testpoints(U):\n",
    "    \"\"\"Read numpy file containing evaluated points for measuring GP error\"\"\"\n",
    "    test_points_file = U.get(\"test_points_file\")\n",
    "    if test_points_file is None:\n",
    "        return None\n",
    "    test_points = np.load(test_points_file)\n",
    "    test_points = repack_fields(test_points[[\"x\", \"f\"]])\n",
    "    return test_points\n",
    "\n",
    "\n",
    "def _compare_testpoints(my_gp, test_points, persis_info):\n",
    "    \"\"\"Compare model at test points\"\"\"\n",
    "    if test_points is None:\n",
    "        return\n",
    "    f_est = my_gp.posterior_mean(test_points[\"x\"])[\"f(x)\"]\n",
    "    mse = np.mean((f_est - test_points[\"f\"]) ** 2)\n",
    "    persis_info.setdefault(\"mean_squared_error\", []).append(float(mse))\n",
    "\n",
    "\n",
    "def _update_gp(my_gp, x_new, y_new, test_points, persis_info, noise):\n",
    "    \"\"\"Update Gaussian process with new points and train\"\"\"\n",
    "    noise_arr = noise * np.ones(len(y_new))  # Initializes noise\n",
    "    if my_gp is None:\n",
    "        my_gp = GP(x_new, y_new.flatten(), noise_variances=noise_arr)\n",
    "    else:\n",
    "        my_gp.tell(x_new, y_new.flatten(), noise_variances=noise_arr, append=True)\n",
    "    my_gp.train()\n",
    "    \n",
    "    if test_points is not None:\n",
    "        _compare_testpoints(my_gp, test_points, persis_info)\n",
    "\n",
    "    return my_gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator function\n",
    "\n",
    "Simulator functions or `sim_f`s perform calculations based on parameters created in the generator function.\n",
    "Each worker will run a copy of this function in parallel.\n",
    "\n",
    "The function used here is the simple 2D `six_hump_camel`, for demonstration purposes.\n",
    "\n",
    "For running parallel applications in the simulator see the [forces examples](https://github.com/Libensemble/libensemble/tree/main/libensemble/tests/scaling_tests/forces/forces_simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our simulation function\n",
    "import numpy as np\n",
    "\n",
    "def six_hump_camel(H, persis_info, sim_specs, _):\n",
    "    \"\"\"Six-Hump Camel sim_f.\"\"\"\n",
    "    \n",
    "    batch = len(H[\"x\"])  # Num evaluations each sim_f call.\n",
    "    H_o = np.zeros(batch, dtype=sim_specs[\"out\"])  # Define output array H\n",
    "    \n",
    "    for i, x in enumerate(H[\"x\"]):\n",
    "        H_o[\"f\"][i] = six_hump_camel_func(x)  # Function evaluations placed into H\n",
    "        \n",
    "    return H_o, persis_info\n",
    "\n",
    "\n",
    "def six_hump_camel_func(x):\n",
    "    \"\"\"Six-Hump Camel function definition\"\"\"\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    term1 = (4 - 2.1 * x1**2 + (x1**4) / 3) * x1**2\n",
    "    term2 = x1 * x2\n",
    "    term3 = (-4 + 4 * x2**2) * x2**2\n",
    "    \n",
    "    return term1 + term2 + term3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Script\n",
    "\n",
    "Our calling script contains the configuration for libEnsemble, the generator function, and the simulator function. We then create the ensemble object and are ready to run the ensemble.\n",
    "\n",
    "First we will create a cleanup script so we can easily re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rerun this notebook, we need to delete the ensemble directory.\n",
    "import shutil\n",
    "def cleanup():\n",
    "    try:\n",
    "        shutil.rmtree(\"ensemble\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from libensemble import Ensemble\n",
    "from libensemble.specs import LibeSpecs, GenSpecs, SimSpecs, AllocSpecs, ExitCriteria \n",
    "\n",
    "# If importing from libensemble\n",
    "# from libensemble.gen_funcs.persistent_gpCAM import persistent_gpCAM\n",
    "# from libensemble.sim_funcs.six_hump_camel import six_hump_camel\n",
    "from libensemble.alloc_funcs.start_only_persistent import only_persistent_gens\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Default hyperparameter_bounds\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Hyperparameters initialized\")\n",
    "\n",
    "nworkers = 4\n",
    "\n",
    "# When using gen_on_manager, nworkers is number of concurrent sims.\n",
    "# final_gen_send means the last evaluated points are returned to the generator to update the model.\n",
    "libE_specs = LibeSpecs(nworkers=nworkers, gen_on_manager=True, final_gen_send=True)\n",
    "\n",
    "n = 2  # Input dimensions\n",
    "batch_size = 4\n",
    "num_batches = 6\n",
    "\n",
    "gen_specs = GenSpecs(\n",
    "    gen_f=persistent_gpCAM,        # Generator function\n",
    "    persis_in=[\"f\"],               # Objective, defined in sim, is returned to gen\n",
    "    outputs=[(\"x\", float, (n,))],  # Parameters (name, type, size)\n",
    "    user={\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lb\": np.array([-2, -1]),  # lower boundaries for n dimensions\n",
    "        \"ub\": np.array([2, 1]),    # upper boundaries for n dimensions        \n",
    "        \"ask_max_iter\": 5,         # Number of iterations for ask\n",
    "        \"rng_seed\": 0,\n",
    "    },\n",
    ")\n",
    "\n",
    "sim_specs = SimSpecs(\n",
    "    sim_f=six_hump_camel,      # Simulator function\n",
    "    inputs=[\"x\"],              # Input field names. \"x\" defined in gen\n",
    "    outputs=[(\"f\", float)],    # Objective\n",
    ")\n",
    "\n",
    "# Starts one persistent generator. Simulated values are returned in batch.\n",
    "alloc_specs = AllocSpecs(\n",
    "    alloc_f=only_persistent_gens,\n",
    "    user={\"async_return\": False},  # False = batch returns\n",
    ")\n",
    "\n",
    "exit_criteria = ExitCriteria(sim_max=num_batches*batch_size)\n",
    "\n",
    "# Initialize and run the ensemble.\n",
    "ensemble = Ensemble(\n",
    "    libE_specs=libE_specs,\n",
    "    sim_specs=sim_specs,\n",
    "    gen_specs=gen_specs,\n",
    "    alloc_specs=alloc_specs,\n",
    "    exit_criteria=exit_criteria,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of our calling script we run the ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure re-running works - clean output and reset any persistent information\n",
    "cleanup()\n",
    "ensemble.persis_info = {}\n",
    "\n",
    "H, persis_info, flag = ensemble.run()  # Start the ensemble. Blocks until completion.\n",
    "ensemble.save_output(\"H_array\", append_attrs=False)  # Save H (history of all evaluated points) to file\n",
    "pprint(H[[\"sim_id\", \"x\", \"f\"]][:16]) # See first 16 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun and test model at known points\n",
    "\n",
    "To see how our model improves, we can use our existing points as test points and run again with a different seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.gen_specs.user[\"rng_seed\"] = 123\n",
    "ensemble.gen_specs.user[\"test_points_file\"] = \"H_array.npy\"  # our previous file\n",
    "\n",
    "# To ensure re-running works - clean output and reset any persistent information\n",
    "cleanup()\n",
    "ensemble.persis_info = {}\n",
    "\n",
    "H, persis_info, flag = ensemble.run()\n",
    "print(persis_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing model progression\n",
    "Now we can check how our model compared against the known test points at each iteration.\n",
    "The comparison is based on the ***Mean Squared Error*** between the gpCAM model and our known\n",
    "values at the test points.\n",
    "\n",
    "> **Note:** The graph may differ between runs because, although we seed libEnsemble's random number generator,  \n",
    "> gpCAM introduces some randomness when initializing hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get \"mean_squared_error\" from generators return (worker 0 as we ran gen_on_manager)\n",
    "mse = persis_info[0][\"mean_squared_error\"]\n",
    "niter = len(mse)\n",
    "num_sims = list(range(batch_size, (niter * batch_size) + 1, batch_size))\n",
    "\n",
    "# Plotting the data\n",
    "markersize = 10\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    num_sims, mse, marker=\"^\", markeredgecolor=\"black\", markeredgewidth=2, \n",
    "    markersize=markersize, linewidth=2, label=\"Mean squared error\"\n",
    ")\n",
    "plt.xticks(num_sims)\n",
    "\n",
    "# Labeling the axes and the legend\n",
    "plt.title('Mean Squared Error at test points')\n",
    "plt.xlabel(\"Number of simulations\")\n",
    "plt.ylabel('Mean squared error (rad$^2$)')\n",
    "legend = plt.legend(framealpha=1, edgecolor=\"black\")  # Increase edge width here\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
